<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>YBot Test Area</title>
    <style>
        body {
            margin: 0;
            padding: 0;
            background: #f0f0f0;
            font-family: Arial, sans-serif;
            overflow: hidden;
        }

        #container {
            width: 100vw;
            height: 100vh;
            position: relative;
        }

        #info {
            position: absolute;
            top: 10px;
            left: 10px;
            background: rgba(0, 0, 0, 0.7);
            color: white;
            padding: 10px;
            border-radius: 5px;
            font-size: 14px;
            z-index: 100;
        }

        #controls {
            position: absolute;
            top: 10px;
            right: 10px;
            background: rgba(0, 0, 0, 0.7);
            color: white;
            padding: 10px;
            border-radius: 5px;
            font-size: 12px;
            z-index: 100;
        }
    </style>
</head>
<body>
    <div id="info">
        <h3>YBot Test Area</h3>
        <p>Mouse: Left-click orbit | Wheel: Zoom | Right-click: Context menu</p>
    </div>

    <div id="controls">
        <strong>Consciousness Level:</strong><br>
        <div id="consciousnessBar" style="width: 200px; height: 8px; background: #333; border-radius: 4px; margin-bottom: 10px;">
            <div id="consciousnessFill" style="width: 0%; height: 100%; background: linear-gradient(90deg, #ff4444, #44ff44); border-radius: 4px; transition: width 0.5s;"></div>
        </div>
        <div id="consciousnessStatus" style="font-size: 11px; color: #888; margin-bottom: 10px;">ü§ñ Initializing consciousness...</div>
        <strong>Pose Presets:</strong><br>
        <button onclick="applyPosePreset('wave')">Wave Hello</button>
        <button onclick="applyPosePreset('point')">Point</button><br>
        <button onclick="applyPosePreset('dance')">Dance</button>
        <button onclick="applyPosePreset('idle')">Relax</button><br><br>
        <strong>LLM Provider:</strong><br>
        <select id="llmProvider" onchange="switchLLMProvider(this.value)">
            <option value="webllm">WebLLM (Local Llama-2)</option>
            <option value="openai">OpenAI GPT-4</option>
            <option value="anthropic">Anthropic Claude</option>
            <option value="ollama">Ollama (Local)</option>
            <option value="lmstudio">LM Studio (Local)</option>
            <option value="together">Together AI</option>
        </select><br>
        <div id="openaiConfig" style="display: none;">
            <input id="openaiKey" type="password" placeholder="OpenAI API Key" style="width: 200px;"><br>
            <small style="color: #ccc;">Get key from: <a href="https://platform.openai.com/api-keys" target="_blank" style="color: #4a9eff;">OpenAI Platform</a></small><br>
        </div>
        <div id="anthropicConfig" style="display: none;">
            <input id="anthropicKey" type="password" placeholder="Anthropic API Key" style="width: 200px;"><br>
            <small style="color: #ccc;">Get key from: <a href="https://console.anthropic.com/" target="_blank" style="color: #4a9eff;">Anthropic Console</a></small><br>
        </div>
        <div id="ollamaConfig" style="display: none;">
            <input id="ollamaModel" placeholder="Model name (e.g., llama2:7b)" style="width: 200px;"><br>
            <small style="color: #ccc;">Install: <a href="https://ollama.ai" target="_blank" style="color: #4a9eff;">ollama.ai</a> | Run: ollama serve</small><br>
        </div>
        <div id="lmstudioConfig" style="display: none;">
            <input id="lmstudioUrl" placeholder="http://localhost:1234" style="width: 200px;"><br>
            <small style="color: #ccc;">Download: <a href="https://lmstudio.ai" target="_blank" style="color: #4a9eff;">LM Studio</a></small><br>
        </div>
        <div id="togetherConfig" style="display: none;">
            <input id="togetherKey" type="password" placeholder="Together AI API Key" style="width: 200px;"><br>
            <small style="color: #ccc;">Get key from: <a href="https://together.ai" target="_blank" style="color: #4a9eff;">Together AI</a></small><br>
        </div>
        <strong>LLM Input:</strong><br>
        <input id="llmInput" placeholder="Describe pose (wave, point, dance, relax, or natural language)" style="width: 250px;"><br>
                <button onclick="testIKSystem()">üß™ Test IK System</button>
        <button onclick="generatePoseFromLLM(document.getElementById('llmInput').value)">ü§ñ Generate with LLM</button>
        <button onclick="parseLLMPose(document.getElementById('llmInput').value)">Quick Apply</button><br>
        <button onclick="undoPose()" style="margin-top: 5px;">‚Ü∂ Undo</button>
        <button onclick="redoPose()" style="margin-top: 5px;">‚Ü∑ Redo</button>
        <div id="llmStatus" style="margin-top: 5px; font-size: 12px; color: #ffa500;">‚è≥ Loading LLM...</div>
        <div id="llmResponse" style="margin-top: 5px; font-size: 12px; color: #ccc;"></div>
    </div>

    <div id="container"></div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/fflate@0.8.0/umd/index.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/loaders/FBXLoader.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/controls/OrbitControls.js"></script>
    <!-- Custom IK solver implementation - no external IK library needed -->
    <script>
let scene, camera, renderer;
let ybot, ground;
let ybotInstance; // YBot class instance
let ikTargets = {}; // Keep for UI compatibility
let ikFrameCounter = 0; // For IK update damping
let lastTime = 0; // For physics delta time
let collisionSystem; // Collision detection system
let llmEngine;
let poseHistory = [];
let currentPoseIndex = -1;
let llmProvider = 'webllm'; // 'webllm' or 'openai'
let openaiApiKey = '';

        // Collision system
        class CollisionSystem {
            constructor() {
                this.colliders = [];
            }

            addCollider(collider) {
                this.colliders.push(collider);
            }

            checkCollisions(object) {
                for (const collider of this.colliders) {
                    if (collider.checkCollision(object)) {
                        return collider.resolveCollision(object);
                    }
                }
                return null;
            }
        }

        class FloorCollider {
            constructor(yLevel = 0) {
                this.yLevel = yLevel;
                this.normal = new THREE.Vector3(0, 1, 0); // Upward normal
            }

            checkCollision(ybot) {
                // Safety check - ensure YBot is properly initialized
                if (!ybot || !ybot.object3D) return false;

                // Check if YBot's feet are below floor level
                if (ybot.getBone) {
                    const leftFoot = ybot.getBone('mixamorigLeftFoot');
                    const rightFoot = ybot.getBone('mixamorigRightFoot');

                    if (leftFoot || rightFoot) {
                        let lowestPoint = Infinity;
                        if (leftFoot) {
                            const pos = new THREE.Vector3();
                            leftFoot.getWorldPosition(pos);
                            lowestPoint = Math.min(lowestPoint, pos.y);
                        }
                        if (rightFoot) {
                            const pos = new THREE.Vector3();
                            rightFoot.getWorldPosition(pos);
                            lowestPoint = Math.min(lowestPoint, pos.y);
                        }
                        return lowestPoint <= this.yLevel;
                    }
                }

                // Fallback to object position
                return ybot.object3D.position.y <= this.yLevel;
            }

            resolveCollision(ybot) {
                // Safety check - ensure YBot is properly initialized
                if (!ybot || !ybot.object3D) return null;

                // Get the lowest foot position
                let lowestPoint = ybot.object3D.position.y;
                if (ybot.getBone) {
                    const leftFoot = ybot.getBone('mixamorigLeftFoot');
                    const rightFoot = ybot.getBone('mixamorigRightFoot');

                    if (leftFoot || rightFoot) {
                        if (leftFoot) {
                            const pos = new THREE.Vector3();
                            leftFoot.getWorldPosition(pos);
                            lowestPoint = Math.min(lowestPoint, pos.y);
                        }
                        if (rightFoot) {
                            const pos = new THREE.Vector3();
                            rightFoot.getWorldPosition(pos);
                            lowestPoint = Math.min(lowestPoint, pos.y);
                        }
                    }
                }

                // Calculate how much to push up
                const penetration = this.yLevel - lowestPoint;
                if (penetration > 0) {
                    ybot.object3D.position.y += penetration;
                }

                return {
                    normal: this.normal,
                    penetration: penetration
                };
            }
        }
let conversationHistory = [];
let posePresets = {
    "wave": {
        leftHand: [0.6, 1.8, 0.4],
        rightHand: [-0.6, 1.8, 0.4],
        description: "Waving both hands"
    },
    "point": {
        leftHand: [0.8, 1.2, 0.6],
        rightHand: [-0.3, 1.0, 0.8],
        description: "Pointing with left hand"
    },
    "dance": {
        leftHand: [0.4, 1.6, 0.2],
        rightHand: [-0.4, 1.6, -0.2],
        description: "Dancing pose"
    },
    "idle": {
        leftHand: [0.2, 0.8, 0.1],
        rightHand: [-0.2, 0.8, 0.1],
        description: "Relaxed standing pose"
    }
};
        // Wait for THREE.js to load before initializing
        function checkLibrariesLoaded() {
            if (typeof THREE !== 'undefined') {
                console.log('THREE.js loaded, initializing...');
                init();
                animate();
            } else {
                console.log('Waiting for THREE.js to load...');
                setTimeout(checkLibrariesLoaded, 100);
            }
        }
        checkLibrariesLoaded();

        function init() {
            // Scene
            scene = new THREE.Scene();
            scene.background = new THREE.Color(0x87CEEB); // Sky blue

            // Camera
            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            // Camera position will be set by updateCameraPosition()

            // Renderer
            renderer = new THREE.WebGLRenderer({ antialias: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.shadowMap.enabled = true;
            renderer.shadowMap.type = THREE.PCFSoftShadowMap;
            document.getElementById('container').appendChild(renderer.domElement);

            // Manual orbit controls (proper implementation)
            let isMouseDown = false;
            let lastMouseX = 0;
            let lastMouseY = 0;
            let cameraDistance = 5;
            let cameraRotationX = 0;
            let cameraRotationY = 0;

            function updateCameraPosition() {
                camera.position.x = cameraDistance * Math.sin(cameraRotationY) * Math.cos(cameraRotationX);
                camera.position.y = cameraDistance * Math.sin(cameraRotationX);
                camera.position.z = cameraDistance * Math.cos(cameraRotationY) * Math.cos(cameraRotationX);
                camera.lookAt(0, 0, 0); // Look at origin (YBot position)
            }

            renderer.domElement.addEventListener('mousedown', function(event) {
                if (event.button === 0) { // Left click only
                    isMouseDown = true;
                    lastMouseX = event.clientX;
                    lastMouseY = event.clientY;
                }
            });

            renderer.domElement.addEventListener('mousemove', function(event) {
                if (isMouseDown) {
                    const deltaX = event.clientX - lastMouseX;
                    const deltaY = event.clientY - lastMouseY;

                    // Update rotation angles
                    cameraRotationY += deltaX * 0.01;
                    cameraRotationX += deltaY * 0.01;

                    // Clamp vertical rotation to prevent flipping
                    cameraRotationX = Math.max(-Math.PI/2, Math.min(Math.PI/2, cameraRotationX));

                    updateCameraPosition();

                    lastMouseX = event.clientX;
                    lastMouseY = event.clientY;
                }
            });

            renderer.domElement.addEventListener('mouseup', function(event) {
                if (event.button === 0) {
                    isMouseDown = false;
                }
            });

            // Zoom with mouse wheel
            renderer.domElement.addEventListener('wheel', function(event) {
                event.preventDefault();
                const zoomSpeed = 0.5;
                cameraDistance += event.deltaY > 0 ? zoomSpeed : -zoomSpeed;
                cameraDistance = Math.max(1, Math.min(20, cameraDistance)); // Clamp distance
                updateCameraPosition();
            });

            // Initialize camera position
            updateCameraPosition();

            // Lighting
            const ambientLight = new THREE.AmbientLight(0x404040, 0.6);
            scene.add(ambientLight);

            const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
            directionalLight.position.set(10, 10, 5);
            directionalLight.castShadow = true;
            directionalLight.shadow.mapSize.width = 2048;
            directionalLight.shadow.mapSize.height = 2048;
            scene.add(directionalLight);

            // Ground
            createGround();

            // Initialize collision system
            collisionSystem = new CollisionSystem();
            const floorCollider = new FloorCollider(0); // Floor at y=0
            collisionSystem.addCollider(floorCollider);

            // Add IK targets to scene
            createIKTargets();

            // Load YBot
            loadYBot();

            // Initialize WebLLM
            initWebLLM();

            // Handle window resize
            window.addEventListener('resize', onWindowResize, false);
        }

        function createGround() {
            const geometry = new THREE.PlaneGeometry(20, 20);
            const material = new THREE.MeshLambertMaterial({
                color: 0x90EE90,
                transparent: true,
                opacity: 0.8
            });
            ground = new THREE.Mesh(geometry, material);
            ground.rotation.x = -Math.PI / 2;
            ground.receiveShadow = true;
            scene.add(ground);

            // Add grid helper
            const gridHelper = new THREE.GridHelper(20, 20);
            scene.add(gridHelper);
        }

        function createIKTargets() {
            // Create visual targets for different body parts
            const targetConfigs = {
                leftHand: { color: 0xff0000, position: [0.5, 1.2, 0.3] },
                rightHand: { color: 0x0000ff, position: [-0.5, 1.2, 0.3] },
                leftFoot: { color: 0xff8800, position: [0.15, 0.05, 0.1] }, // Lower for ground contact
                rightFoot: { color: 0x0088ff, position: [-0.15, 0.05, 0.1] }, // Lower for ground contact
                head: { color: 0x88ff00, position: [0, 1.6, 0] }
            };

            for (const [name, config] of Object.entries(targetConfigs)) {
                ikTargets[name] = new THREE.Mesh(
                    new THREE.SphereGeometry(0.03),
                    new THREE.MeshBasicMaterial({ color: config.color, transparent: true, opacity: 0.7 })
                );
                ikTargets[name].position.set(...config.position);
                ikTargets[name].visible = false; // Hidden by default
                scene.add(ikTargets[name]);
            }
        }

        function loadYBot() {
            const loader = new THREE.FBXLoader();

            loader.load(
                './assets/YBot.fbx',
                function (object) {
                    ybot = object; // Keep for backward compatibility
                    ybotInstance = new YBot();
                    ybotInstance.setObject(object);

                    // Scale and position
                    ybot.scale.setScalar(0.01); // FBX models are often too large
                    ybot.position.set(0, 0, 0);

                    // Enable shadows
                    ybot.traverse(function (child) {
                        if (child.isMesh) {
                            child.castShadow = true;
                            child.receiveShadow = true;
                        }
                    });

                    scene.add(ybot);
                    console.log('YBot loaded successfully');
                    console.log('YBot object:', ybot);
                    console.log('YBot skeleton:', ybot.skeleton);
                    console.log('Skeleton bones count:', ybot.skeleton ? ybot.skeleton.bones.length : 0);

                    // Check if the model has a proper skeleton for IK
                    // More thorough check for bones in FBX structure
                    let hasBones = false;
                    let boneCount = 0;

                    if (ybot.skeleton && ybot.skeleton.bones && ybot.skeleton.bones.length > 0) {
                        hasBones = true;
                        boneCount = ybot.skeleton.bones.length;
                    } else {
                        // Check if bones are stored in children or animations
                        ybot.traverse((child) => {
                            if (child.isBone) {
                                hasBones = true;
                                boneCount++;
                            }
                        });
                    }

                    console.log('Has bones:', hasBones, 'Count:', boneCount);

                    if (!hasBones) {
                        console.warn('YBot model has no skeleton - using rigged placeholder for IK');
                        scene.remove(ybot);
                        createPlaceholderYBot();
                        setTimeout(() => {
                            console.log('Using simple IK with placeholder robot');
                        }, 100);
                        return;
                    }

                    // Initialize IK after YBot loads
                    setTimeout(() => {
                        if (ybotInstance) {
                            ybotInstance.createIKChains();
                            // Set initial targets
                            ybotInstance.setIKTarget('leftHand', [0.5, 1.2, 0.3]);
                            ybotInstance.setIKTarget('rightHand', [-0.5, 1.2, 0.3]);
                            ybotInstance.setIKTarget('leftFoot', [0.15, 0.05, 0.1]);
                            ybotInstance.setIKTarget('rightFoot', [-0.15, 0.05, 0.1]);
                            ybotInstance.setIKTarget('head', [0, 1.6, 0]);
                        }
                    }, 100); // Small delay to ensure bones are ready
                },
                function (progress) {
                    console.log('Loading progress:', (progress.loaded / progress.total * 100) + '%');
                },
                function (error) {
                    console.error('Error loading YBot:', error);
                    // Create a placeholder if loading fails
                    createPlaceholderYBot();
                    setTimeout(() => {
                        console.log('Using simple IK with placeholder robot (fallback)');
                    }, 100);
                }
            );
        }

        function savePoseToHistory(poseData, description) {
            // Remove any poses after current index (for undo/redo)
            poseHistory = poseHistory.slice(0, currentPoseIndex + 1);

            // Save current pose state
            const currentPose = {
                leftHand: ikTargets.leftHand ? ikTargets.leftHand.position.toArray() : null,
                rightHand: ikTargets.rightHand ? ikTargets.rightHand.position.toArray() : null,
                description: description,
                timestamp: Date.now()
            };

            poseHistory.push(currentPose);
            currentPoseIndex = poseHistory.length - 1;

            // Limit history to 50 poses
            if (poseHistory.length > 50) {
                poseHistory.shift();
                currentPoseIndex--;
            }
        }

        function undoPose() {
            if (currentPoseIndex > 0) {
                currentPoseIndex--;
                const pose = poseHistory[currentPoseIndex];
                applySavedPose(pose);
                document.getElementById('llmResponse').textContent = `‚Ü∂ Undid to: ${pose.description}`;
            } else {
                document.getElementById('llmResponse').textContent = '‚Ü∂ Nothing to undo';
            }
        }

        function redoPose() {
            if (currentPoseIndex < poseHistory.length - 1) {
                currentPoseIndex++;
                const pose = poseHistory[currentPoseIndex];
                applySavedPose(pose);
                document.getElementById('llmResponse').textContent = `‚Ü∑ Redid to: ${pose.description}`;
            } else {
                document.getElementById('llmResponse').textContent = '‚Ü∑ Nothing to redo';
            }
        }

        function applySavedPose(pose) {
            if (pose.leftHand) {
                moveIKTarget('leftHand', ...pose.leftHand);
            }
            if (pose.rightHand) {
                moveIKTarget('rightHand', ...pose.rightHand);
            }
        }

        async function initWebLLM() {
            try {
                console.log('WebLLM disabled - using OpenAI fallback...');
                throw new Error('WebLLM disabled for stability');
            } catch (error) {
                console.log('Falling back to OpenAI API...');
                updateLLMStatus('Using OpenAI API');
                llmProvider = 'openai';
                document.getElementById('llmProvider').value = 'openai';
                document.getElementById('openaiConfig').style.display = 'block';
            }
        }

        function switchLLMProvider(provider) {
            llmProvider = provider;

            // Hide all configs
            document.getElementById('openaiConfig').style.display = 'none';
            document.getElementById('anthropicConfig').style.display = 'none';
            document.getElementById('ollamaConfig').style.display = 'none';
            document.getElementById('lmstudioConfig').style.display = 'none';
            document.getElementById('togetherConfig').style.display = 'none';

            // Show selected config and update status
            switch(provider) {
                case 'openai':
                    document.getElementById('openaiConfig').style.display = 'block';
                    updateLLMStatus('üîë Ready for OpenAI GPT-4');
                    break;
                case 'anthropic':
                    document.getElementById('anthropicConfig').style.display = 'block';
                    updateLLMStatus('üß† Ready for Anthropic Claude');
                    break;
                case 'ollama':
                    document.getElementById('ollamaConfig').style.display = 'block';
                    updateLLMStatus('üê™ Ready for Ollama Local LLM');
                    break;
                case 'lmstudio':
                    document.getElementById('lmstudioConfig').style.display = 'block';
                    updateLLMStatus('üé≠ Ready for LM Studio Local LLM');
                    break;
                case 'together':
                    document.getElementById('togetherConfig').style.display = 'block';
                    updateLLMStatus('üöÄ Ready for Together AI');
                    break;
                default: // webllm
                    updateLLMStatus(llmEngine ? 'ü§ñ WebLLM Ready' : '‚ùå WebLLM Offline');
            }
        }

        function updateLLMStatus(message) {
            document.getElementById('llmStatus').textContent = message;
        }




        function animate(currentTime = 0) {
            requestAnimationFrame(animate);

            // Calculate delta time for physics
            const deltaTime = Math.min((currentTime - lastTime) / 1000, 1/30); // Cap at 30 FPS
            lastTime = currentTime;

            ikFrameCounter++;

            // Update physics every frame
            if (ybotInstance) {
                ybotInstance.updatePhysics(deltaTime, collisionSystem);
            }

            // Only update IK every 6 frames for maximum stability
            if (ikFrameCounter % 6 === 0) {
                // Use YBot IK system
                if (ybotInstance && ybotInstance.isInitialized) {
                    ybotInstance.updateIK();
                } else {
                    // Fallback to simple IK if YBot not ready
                    applySimpleIK();
                }
            }

            renderer.render(scene, camera);
        }

        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        }

        function resetCamera() {
            cameraDistance = 5;
            cameraRotationX = 0;
            cameraRotationY = 0;
            updateCameraPosition();
        }

        function toggleWireframe() {
            if (ybot) {
                ybot.traverse(function (child) {
                    if (child.isMesh && child.material) {
                        child.material.wireframe = !child.material.wireframe;
                    }
                });
            }
        }

        function moveIKTarget(targetName, x, y, z) {
            console.log(`Moving IK target ${targetName} to:`, x, y, z);

            // Update visual target
            const target = ikTargets[targetName];
            if (target) {
                target.position.set(x, y, z);
                target.visible = true;
                console.log(`Target ${targetName} position set to:`, target.position);
            }

            // Update YBot IK chain target
            if (ybotInstance && ybotInstance.ikChains[targetName]) {
                try {
                    ybotInstance.setIKTarget(targetName, [x, y, z]);
                    console.log(`YBot IK chain ${targetName} target updated`);
                } catch (chainError) {
                    console.warn(`Error updating YBot IK chain for ${targetName}:`, chainError);
                }
            } else {
                console.warn(`No YBot IK chain found for ${targetName}`);
            }
        }

        // Simple IK implementation for basic arm movement
        function applySimpleIK() {
            if (!ybot) return;

            // Apply simple IK to arms if targets exist and are visible
            if (ikTargets.leftHand && ikTargets.leftHand.visible) {
                applyArmIK('left');
            }

            if (ikTargets.rightHand && ikTargets.rightHand.visible) {
                applyArmIK('right');
            }
        }

        class YBot {
            constructor() {
                this.object3D = null;
                this.bones = [];
                this.ikSolver = new CustomIKSolver();
                this.ikChains = {};
                this.ikTargets = {};
                this.isInitialized = false;

                // Physics properties
                this.velocity = new THREE.Vector3(0, 0, 0);
                this.gravity = -9.8;
                this.groundY = 0.05; // Match foot target height
                this.isGrounded = false;
                this.mass = 70; // kg
                this.damping = 0.95;

                // Collision properties
                this.collisionRadius = 0.3; // Approximate radius for collision
                this.collisionHeight = 1.8; // Approximate height
            }

            setObject(object3D) {
                this.object3D = object3D;
                this.findBones();
            }

            findBones() {
                this.bones = [];
                if (this.object3D) {
                    this.object3D.traverse((child) => {
                        if (child.isBone) {
                            this.bones.push(child);
                        }
                    });
                }
                console.log(`YBot: Found ${this.bones.length} bones`);
            }

            createIKChains() {
                if (!this.object3D || this.bones.length === 0) {
                    console.warn('YBot: Cannot create IK chains - no object or bones');
                    return false;
                }

                const findBone = (name) => {
                    return this.bones.find(bone => bone.name === name);
                };

                // Create chains for different body parts
                const chainConfigs = [
                    { name: 'leftHand', bones: ['mixamorigLeftShoulder', 'mixamorigLeftArm', 'mixamorigLeftForeArm', 'mixamorigLeftHand'] },
                    { name: 'rightHand', bones: ['mixamorigRightShoulder', 'mixamorigRightArm', 'mixamorigRightForeArm', 'mixamorigRightHand'] },
                    { name: 'leftFoot', bones: ['mixamorigLeftUpLeg', 'mixamorigLeftLeg', 'mixamorigLeftFoot'] },
                    { name: 'rightFoot', bones: ['mixamorigRightUpLeg', 'mixamorigRightLeg', 'mixamorigRightFoot'] },
                    { name: 'head', bones: ['mixamorigSpine', 'mixamorigSpine1', 'mixamorigNeck', 'mixamorigHead'] }
                ];

                for (const config of chainConfigs) {
                    const chainBones = config.bones.map(name => findBone(name)).filter(bone => bone);
                    if (chainBones.length >= 2) {
                        const chain = new CustomIKChain();
                        chainBones.forEach(bone => chain.add(bone));
                        this.ikSolver.add(chain);
                        this.ikChains[config.name] = chain;
                        console.log(`YBot: Created ${config.name} IK chain with ${chainBones.length} bones`);
                    } else {
                        console.warn(`YBot: Not enough bones for ${config.name} chain: ${chainBones.length} found`);
                    }
                }

                this.isInitialized = Object.keys(this.ikChains).length > 0;
                console.log(`YBot: IK system initialized with ${Object.keys(this.ikChains).length} chains`);
                return this.isInitialized;
            }

            setIKTarget(chainName, position) {
                if (this.ikChains[chainName]) {
                    const target = new THREE.Vector3().fromArray(position);
                    this.ikChains[chainName].setTarget(target);
                }
            }

            updateIK() {
                if (this.isInitialized) {
                    this.ikSolver.solve();
                    if (this.object3D) {
                        this.object3D.updateMatrixWorld(true);
                    }
                }
            }

            updatePhysics(deltaTime, collisionSystem) {
                if (!this.object3D) return;

                // Apply gravity
                this.velocity.y += this.gravity * deltaTime;

                // Apply damping
                this.velocity.multiplyScalar(this.damping);

                // Store previous position for collision resolution
                const prevPosition = this.object3D.position.clone();

                // Apply velocity to position
                this.object3D.position.add(this.velocity.clone().multiplyScalar(deltaTime));

                // Check collisions
                this.isGrounded = false;
                if (collisionSystem) {
                    const collision = collisionSystem.checkCollisions(this);
                    if (collision) {
                        // Resolve collision
                        this.object3D.position.copy(prevPosition);

                        // Handle floor collision
                        if (collision.normal.y > 0) {
                            this.isGrounded = true;
                            this.velocity.y = Math.max(0, this.velocity.y);

                            // Apply ground friction
                            this.velocity.x *= 0.8;
                            this.velocity.z *= 0.8;
                        }
                    }
                }

                // If no collision system, fall back to simple ground check
                if (!collisionSystem) {
                    // Get foot positions to check grounding
                    const leftFoot = this.getBone('mixamorigLeftFoot');
                    const rightFoot = this.getBone('mixamorigRightFoot');

                    let lowestPoint = 0;
                    if (leftFoot || rightFoot) {
                        const positions = [];
                        if (leftFoot) {
                            const pos = new THREE.Vector3();
                            leftFoot.getWorldPosition(pos);
                            positions.push(pos.y);
                        }
                        if (rightFoot) {
                            const pos = new THREE.Vector3();
                            rightFoot.getWorldPosition(pos);
                            positions.push(pos.y);
                        }
                        lowestPoint = Math.min(...positions);
                    }

                    // Ground collision
                    if (lowestPoint <= this.groundY + 0.05) {
                        this.velocity.y = Math.max(0, this.velocity.y); // Stop downward motion
                        this.isGrounded = true;

                        // Apply ground friction
                        this.velocity.x *= 0.8;
                        this.velocity.z *= 0.8;
                    } else {
                        this.isGrounded = false;
                    }
                }
            }

            getBone(name) {
                return this.bones.find(bone => bone.name === name);
            }
        }
        class CustomIKSolver {
            constructor() {
                this.chains = [];
                this.maxIterations = 1; // Single pass for stability
                this.tolerance = 0.2; // Even higher tolerance
            }

            add(chain) {
                this.chains.push(chain);
            }

            solve() {
                for (const chain of this.chains) {
                    if (chain.target && chain.joints.length > 1) {
                        this.solveChain(chain);
                    }
                }

                // Update the entire YBot object after solving all chains
                if (ybot) {
                    ybot.updateMatrixWorld(true);
                }
            }

            solveChain(chain) {
                const target = chain.target;
                const joints = chain.joints;

                // Ultra-simple IK: just make each joint point towards the target
                // This is more stable than complex CCD algorithms
                for (let i = 0; i < joints.length - 1; i++) {
                    const joint = joints[i];
                    const nextJoint = joints[i + 1];

                    // Get positions
                    const jointPos = new THREE.Vector3();
                    const nextPos = new THREE.Vector3();
                    const targetPos = target.clone();

                    joint.getWorldPosition(jointPos);
                    nextJoint.getWorldPosition(nextPos);

                    // Vector from joint to next joint (current bone direction)
                    const currentDir = new THREE.Vector3().subVectors(nextPos, jointPos).normalize();

                    // Vector from joint to target
                    const targetDir = new THREE.Vector3().subVectors(targetPos, jointPos).normalize();

                    // Calculate rotation needed
                    const dot = Math.max(-1, Math.min(1, currentDir.dot(targetDir)));
                    const angle = Math.acos(dot);

                    if (angle > 0.01) {
                        // Calculate rotation axis
                        const axis = new THREE.Vector3().crossVectors(currentDir, targetDir).normalize();

                        // Very small rotation for stability
                        const maxAngle = Math.PI / 12; // 15 degrees max
                        const clampedAngle = Math.min(angle * 0.05, maxAngle);

                        if (clampedAngle > 0.001) {
                            // Apply rotation in world space, then convert to local
                            const worldQuat = new THREE.Quaternion();
                            joint.getWorldQuaternion(worldQuat);

                            const rotation = new THREE.Quaternion().setFromAxisAngle(axis, clampedAngle);
                            worldQuat.multiply(rotation);

                            // Convert back to local quaternion
                            if (joint.parent) {
                                const parentWorldQuat = new THREE.Quaternion();
                                joint.parent.getWorldQuaternion(parentWorldQuat);
                                parentWorldQuat.invert();
                                joint.quaternion.copy(parentWorldQuat).multiply(worldQuat);
                            } else {
                                joint.quaternion.copy(worldQuat);
                            }

                            // Update matrices
                            joint.updateMatrix();
                        }
                    }
                }
            }
        }

        class CustomIKChain {
            constructor() {
                this.joints = [];
                this.target = null;
            }

            add(joint) {
                this.joints.push(joint);
            }

            setTarget(position) {
                this.target = position.clone();
            }
        }

        function applyPosePreset(presetName) {
            const preset = posePresets[presetName];
            if (!preset) return;

            console.log('Applying pose:', preset.description);

            // Apply hand positions
            if (preset.leftHand) {
                moveIKTarget('leftHand', ...preset.leftHand);
            }
            if (preset.rightHand) {
                moveIKTarget('rightHand', ...preset.rightHand);
            }

            // Show targets briefly for visual feedback
            showTargetsTemporarily();
        }

        function showTargetsTemporarily() {
            // Make targets visible for 2 seconds
            Object.values(ikTargets).forEach(target => {
                target.visible = true;
            });

            setTimeout(() => {
                Object.values(ikTargets).forEach(target => {
                    target.visible = false;
                });
            }, 2000);
        }

        function parseLLMPose(text) {
            // Simple LLM pose parser - can be enhanced
            const lowerText = text.toLowerCase();
            const responseDiv = document.getElementById('llmResponse');

            if (lowerText.includes('wave') || lowerText.includes('hello')) {
                applyPosePreset('wave');
                responseDiv.textContent = 'ü§ñ Applied waving pose';
                return 'Applied waving pose';
            }
            if (lowerText.includes('point')) {
                applyPosePreset('point');
                responseDiv.textContent = 'ü§ñ Applied pointing pose';
                return 'Applied pointing pose';
            }
            if (lowerText.includes('dance')) {
                applyPosePreset('dance');
                responseDiv.textContent = 'ü§ñ Applied dancing pose';
                return 'Applied dancing pose';
            }
            if (lowerText.includes('relax') || lowerText.includes('idle')) {
                applyPosePreset('idle');
                responseDiv.textContent = 'ü§ñ Applied relaxed pose';
                return 'Applied relaxed pose';
            }

            responseDiv.textContent = 'ü§ñ Pose not recognized. Try: wave, point, dance, or relax';
            return 'Pose not recognized. Try: wave, point, dance, or relax';
        }

        async function generatePoseFromLLM(text) {
            const responseDiv = document.getElementById('llmResponse');
            responseDiv.textContent = 'ÔøΩ Thinking...';

            // Activate consciousness thinking mode
            startThinkingAnimation();

            try {
                let poseData;
                console.log('Using LLM provider:', llmProvider);

                switch(llmProvider) {
                    case 'openai':
                        console.log('Calling OpenAI...');
                        poseData = await generateWithOpenAI(text);
                        break;
                    case 'anthropic':
                        console.log('Calling Anthropic...');
                        poseData = await generateWithAnthropic(text);
                        break;
                    case 'ollama':
                        console.log('Calling Ollama...');
                        poseData = await generateWithOllama(text);
                        break;
                    case 'lmstudio':
                        console.log('Calling LM Studio...');
                        poseData = await generateWithLMStudio(text);
                        break;
                    case 'together':
                        console.log('Calling Together AI...');
                        poseData = await generateWithTogether(text);
                        break;
                    default: // webllm
                        console.log('WebLLM available:', !!llmEngine);
                        if (llmEngine) {
                            poseData = await generateWithWebLLM(text);
                        } else {
                            console.log('WebLLM not available, trying to load it...');
                            try {
                                // Try to load WebLLM on demand
                                await initWebLLM();
                                if (llmEngine) {
                                    poseData = await generateWithWebLLM(text);
                                } else {
                                    throw new Error('WebLLM still not available');
                                }
                            } catch (webllmError) {
                                console.log('WebLLM failed, switching to OpenAI...');
                                llmProvider = 'openai';
                                document.getElementById('llmProvider').value = 'openai';
                                document.getElementById('openaiConfig').style.display = 'block';
                                poseData = await generateWithOpenAI(text);
                            }
                        }
                }

                if (poseData) {
                    console.log('LLM generated pose data:', poseData);
                    applyLLMPose(poseData);
                    savePoseToHistory(poseData, poseData.description || 'LLM pose');
                    responseDiv.textContent = `ü§ñ Applied: ${poseData.description || 'LLM pose'}`;
                } else {
                    console.error('No pose data returned from LLM');
                    throw new Error('No pose data generated');
                }

            } catch (error) {
                console.error('LLM generation failed:', error);
                responseDiv.textContent = '‚ùå LLM Error - using basic parser';
                // Force test with basic parser
                console.log('Testing with basic parser...');
                parseLLMPose(text); // Fallback
            }
        }

        async function generateWithWebLLM(text) {
            // Enhanced prompt with conversation history
            const historyContext = conversationHistory.slice(-3).map(h => `User: ${h.input}\nAI: ${h.output}`).join('\n');
            const prompt = `${historyContext ? `Previous conversation:\n${historyContext}\n\n` : ''}Convert this pose description into specific IK target positions for a humanoid robot.
                    Description: "${text}"
                    
                    Respond with JSON format like:
                    {
                        "leftHand": [x, y, z],
                        "rightHand": [x, y, z],
                        "description": "brief description"
                    }
                    
                    Use coordinates relative to robot center, where:
                    - Forward is +Z, Back is -Z
                    - Right is +X, Left is -X  
                    - Up is +Y, Down is -Y
                    - Normal reach distance is about 0.5-0.8 units
                    
                    Examples:
                    "wave hello" -> {"leftHand": [0.6, 1.8, 0.4], "rightHand": [-0.6, 1.8, 0.4], "description": "waving both hands"}
                    "point forward" -> {"leftHand": [0.8, 1.2, 0.6], "rightHand": [-0.2, 0.8, 0.1], "description": "pointing with left hand"}
                    "hands up" -> {"leftHand": [0.5, 2.0, 0.2], "rightHand": [-0.5, 2.0, 0.2], "description": "raising both hands up"}
                    `;

            const reply = await llmEngine.generate(prompt, { max_gen_len: 300 });
            console.log('WebLLM raw response:', reply);

            // Try to parse JSON from response
            const jsonMatch = reply.match(/\{[\s\S]*\}/);
            if (jsonMatch) {
                const poseData = JSON.parse(jsonMatch[0]);
                console.log('Parsed pose data:', poseData);
                conversationHistory.push({ input: text, output: JSON.stringify(poseData) });
                return poseData;
            }
            console.error('No JSON found in WebLLM response:', reply);
            throw new Error('No JSON found in WebLLM response');
        }

        async function generateWithAnthropic(text) {
            const apiKey = document.getElementById('anthropicKey').value.trim();
            if (!apiKey) {
                throw new Error('Anthropic API key required');
            }

            const messages = [
                {
                    role: 'user',
                    content: `Convert this pose description into specific IK target positions for a humanoid robot.
                    Description: "${text}"

                    Respond with JSON format like:
                    {
                        "leftHand": [x, y, z],
                        "rightHand": [x, y, z],
                        "description": "brief description"
                    }

                    Use coordinates relative to robot center, where:
                    - Forward is +Z, Back is -Z
                    - Right is +X, Left is -X
                    - Up is +Y, Down is -Y
                    - Normal reach distance is about 0.5-0.8 units

                    Examples:
                    "wave hello" -> {"leftHand": [0.6, 1.8, 0.4], "rightHand": [-0.6, 1.8, 0.4], "description": "waving both hands"}
                    "point forward" -> {"leftHand": [0.8, 1.2, 0.6], "rightHand": [-0.2, 0.8, 0.1], "description": "pointing with left hand"}`
                }
            ];

            const response = await fetch('https://api.anthropic.com/v1/messages', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'x-api-key': apiKey,
                    'anthropic-version': '2023-06-01'
                },
                body: JSON.stringify({
                    model: 'claude-3-haiku-20240307',
                    messages: messages,
                    max_tokens: 300,
                    temperature: 0.3
                })
            });

            if (!response.ok) {
                throw new Error(`Anthropic API error: ${response.status}`);
            }

            const data = await response.json();
            const content = data.content[0].text.trim();

            // Try to parse JSON
            try {
                const poseData = JSON.parse(content);
                conversationHistory.push({ input: text, output: JSON.stringify(poseData) });
                return poseData;
            } catch (parseError) {
                // Try to extract JSON from text
                const jsonMatch = content.match(/\{[\s\S]*\}/);
                if (jsonMatch) {
                    const poseData = JSON.parse(jsonMatch[0]);
                    conversationHistory.push({ input: text, output: JSON.stringify(poseData) });
                    return poseData;
                }
                throw new Error('Invalid JSON in Anthropic response');
            }
        }

        async function generateWithOllama(text) {
            const modelName = document.getElementById('ollamaModel').value.trim() || 'llama2:7b';

            const prompt = `Convert this pose description into specific IK target positions for a humanoid robot.
            Description: "${text}"

            Respond with JSON format like:
            {
                "leftHand": [x, y, z],
                "rightHand": [x, y, z],
                "description": "brief description"
            }

            Use coordinates relative to robot center, where:
            - Forward is +Z, Back is -Z
            - Right is +X, Left is -X
            - Up is +Y, Down is -Y
            - Normal reach distance is about 0.5-0.8 units

            Examples:
            "wave hello" -> {"leftHand": [0.6, 1.8, 0.4], "rightHand": [-0.6, 1.8, 0.4], "description": "waving both hands"}
            "point forward" -> {"leftHand": [0.8, 1.2, 0.6], "rightHand": [-0.2, 0.8, 0.1], "description": "pointing with left hand"}`;

            const response = await fetch('http://localhost:11434/api/generate', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    model: modelName,
                    prompt: prompt,
                    stream: false,
                    options: {
                        temperature: 0.3,
                        num_predict: 200
                    }
                })
            });

            if (!response.ok) {
                throw new Error(`Ollama API error: ${response.status}`);
            }

            const data = await response.json();
            const content = data.response.trim();

            // Try to parse JSON
            try {
                const poseData = JSON.parse(content);
                conversationHistory.push({ input: text, output: JSON.stringify(poseData) });
                return poseData;
            } catch (parseError) {
                // Try to extract JSON from text
                const jsonMatch = content.match(/\{[\s\S]*\}/);
                if (jsonMatch) {
                    const poseData = JSON.parse(jsonMatch[0]);
                    conversationHistory.push({ input: text, output: JSON.stringify(poseData) });
                    return poseData;
                }
                throw new Error('Invalid JSON in Ollama response');
            }
        }

        async function generateWithLMStudio(text) {
            const baseUrl = document.getElementById('lmstudioUrl').value.trim() || 'http://localhost:1234';

            const messages = [
                {
                    role: 'user',
                    content: `Convert this pose description into specific IK target positions for a humanoid robot.
                    Description: "${text}"

                    Respond with JSON format like:
                    {
                        "leftHand": [x, y, z],
                        "rightHand": [x, y, z],
                        "description": "brief description"
                    }

                    Use coordinates relative to robot center, where:
                    - Forward is +Z, Back is -Z
                    - Right is +X, Left is -X
                    - Up is +Y, Down is -Y
                    - Normal reach distance is about 0.5-0.8 units

                    Examples:
                    "wave hello" -> {"leftHand": [0.6, 1.8, 0.4], "rightHand": [-0.6, 1.8, 0.4], "description": "waving both hands"}
                    "point forward" -> {"leftHand": [0.8, 1.2, 0.6], "rightHand": [-0.2, 0.8, 0.1], "description": "pointing with left hand"}`
                }
            ];

            const response = await fetch(`${baseUrl}/v1/chat/completions`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    messages: messages,
                    max_tokens: 300,
                    temperature: 0.3
                })
            });

            if (!response.ok) {
                throw new Error(`LM Studio API error: ${response.status}`);
            }

            const data = await response.json();
            const content = data.choices[0].message.content.trim();

            // Try to parse JSON
            try {
                const poseData = JSON.parse(content);
                conversationHistory.push({ input: text, output: JSON.stringify(poseData) });
                return poseData;
            } catch (parseError) {
                // Try to extract JSON from text
                const jsonMatch = content.match(/\{[\s\S]*\}/);
                if (jsonMatch) {
                    const poseData = JSON.parse(jsonMatch[0]);
                    conversationHistory.push({ input: text, output: JSON.stringify(poseData) });
                    return poseData;
                }
                throw new Error('Invalid JSON in LM Studio response');
            }
        }

        async function generateWithTogether(text) {
            const apiKey = document.getElementById('togetherKey').value.trim();
            if (!apiKey) {
                throw new Error('Together AI API key required');
            }

            const messages = [
                {
                    role: 'user',
                    content: `Convert this pose description into specific IK target positions for a humanoid robot.
                    Description: "${text}"

                    Respond with JSON format like:
                    {
                        "leftHand": [x, y, z],
                        "rightHand": [x, y, z],
                        "description": "brief description"
                    }

                    Use coordinates relative to robot center, where:
                    - Forward is +Z, Back is -Z
                    - Right is +X, Left is -X
                    - Up is +Y, Down is -Y
                    - Normal reach distance is about 0.5-0.8 units

                    Examples:
                    "wave hello" -> {"leftHand": [0.6, 1.8, 0.4], "rightHand": [-0.6, 1.8, 0.4], "description": "waving both hands"}
                    "point forward" -> {"leftHand": [0.8, 1.2, 0.6], "rightHand": [-0.2, 0.8, 0.1], "description": "pointing with left hand"}`
                }
            ];

            const response = await fetch('https://api.together.xyz/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${apiKey}`
                },
                body: JSON.stringify({
                    model: 'meta-llama/Llama-2-70b-chat-hf',
                    messages: messages,
                    max_tokens: 300,
                    temperature: 0.3
                })
            });

            if (!response.ok) {
                throw new Error(`Together AI API error: ${response.status}`);
            }

            const data = await response.json();
            const content = data.choices[0].message.content.trim();

            // Try to parse JSON
            try {
                const poseData = JSON.parse(content);
                conversationHistory.push({ input: text, output: JSON.stringify(poseData) });
                return poseData;
            } catch (parseError) {
                // Try to extract JSON from text
                const jsonMatch = content.match(/\{[\s\S]*\}/);
                if (jsonMatch) {
                    const poseData = JSON.parse(jsonMatch[0]);
                    conversationHistory.push({ input: text, output: JSON.stringify(poseData) });
                    return poseData;
                }
                throw new Error('Invalid JSON in Together AI response');
            }
        }

        function applyLLMPose(poseData) {
            console.log('Applying LLM pose:', poseData);

            // Apply hand positions if specified
            if (poseData.leftHand && Array.isArray(poseData.leftHand)) {
                console.log('Moving left hand to:', poseData.leftHand);
                moveIKTarget('leftHand', ...poseData.leftHand);
            }
            if (poseData.rightHand && Array.isArray(poseData.rightHand)) {
                console.log('Moving right hand to:', poseData.rightHand);
                moveIKTarget('rightHand', ...poseData.rightHand);
            }

            // Apply additional body parts if specified
            if (poseData.leftFoot && Array.isArray(poseData.leftFoot)) {
                moveIKTarget('leftFoot', ...poseData.leftFoot);
            }
            if (poseData.rightFoot && Array.isArray(poseData.rightFoot)) {
                moveIKTarget('rightFoot', ...poseData.rightFoot);
            }
            if (poseData.head && Array.isArray(poseData.head)) {
                moveIKTarget('head', ...poseData.head);
            }

            // Show targets briefly
            showTargetsTemporarily();
        }

        function testIKSystem() {
            console.log('Testing IK system...');
            // Test by moving left hand to a visible position
            moveIKTarget('leftHand', 0.8, 1.2, 0.6);
            document.getElementById('llmResponse').textContent = 'üß™ IK Test: Moved left hand forward';
        }

        async function generateWithOpenAI(text) {
            const apiKey = document.getElementById('openaiKey').value.trim();
            if (!apiKey) {
                throw new Error('OpenAI API key required');
            }

            const historyContext = conversationHistory.slice(-3).map(h => ({
                role: 'user',
                content: h.input
            })).concat(conversationHistory.slice(-3).map(h => ({
                role: 'assistant',
                content: h.output
            })));

            const messages = [
                {
                    role: 'system',
                    content: `You are a pose generation AI for a humanoid robot. Convert natural language descriptions into specific 3D coordinates for inverse kinematics.

Use coordinates relative to robot center:
- Forward is +Z, Back is -Z
- Right is +X, Left is -X
- Up is +Y, Down is -Y
- Normal reach distance is about 0.5-0.8 units

Always respond with valid JSON in this exact format:
{
    "leftHand": [x, y, z],
    "rightHand": [x, y, z],
    "description": "brief description of the pose"
}`
                },
                ...historyContext,
                {
                    role: 'user',
                    content: `Generate pose coordinates for: "${text}"`
                }
            ];

            const response = await fetch('https://api.openai.com/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${apiKey}`
                },
                body: JSON.stringify({
                    model: 'gpt-4o-mini',
                    messages: messages,
                    max_tokens: 200,
                    temperature: 0.3
                })
            });

            if (!response.ok) {
                throw new Error(`OpenAI API error: ${response.status}`);
            }

            const data = await response.json();
            const content = data.choices[0].message.content.trim();

            // Try to parse JSON
            try {
                const poseData = JSON.parse(content);
                conversationHistory.push({ input: text, output: JSON.stringify(poseData) });
                return poseData;
            } catch (parseError) {
                // Try to extract JSON from text
                const jsonMatch = content.match(/\{[\s\S]*\}/);
                if (jsonMatch) {
                    const poseData = JSON.parse(jsonMatch[0]);
                    conversationHistory.push({ input: text, output: JSON.stringify(poseData) });
                    return poseData;
                }
                throw new Error('Invalid JSON in OpenAI response');
            }
        }

        async function generateWithOllama(text) {
            const modelName = document.getElementById('ollamaModel').value.trim() || 'llama2:7b';

            const prompt = `Convert this pose description into specific IK target positions for a humanoid robot.
            Description: "${text}"

            Respond with JSON format like:
            {
                "leftHand": [x, y, z],
                "rightHand": [x, y, z],
                "description": "brief description"
            }

            Use coordinates relative to robot center, where:
            - Forward is +Z, Back is -Z
            - Right is +X, Left is -X
            - Up is +Y, Down is -Y
            - Normal reach distance is about 0.5-0.8 units

            Examples:
            "wave hello" -> {"leftHand": [0.6, 1.8, 0.4], "rightHand": [-0.6, 1.8, 0.4], "description": "waving both hands"}
            "point forward" -> {"leftHand": [0.8, 1.2, 0.6], "rightHand": [-0.2, 0.8, 0.1], "description": "pointing with left hand"}`;

            const response = await fetch('http://localhost:11434/api/generate', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    model: modelName,
                    prompt: prompt,
                    stream: false,
                    options: {
                        temperature: 0.3,
                        num_predict: 200
                    }
                })
            });

            if (!response.ok) {
                throw new Error(`Ollama API error: ${response.status}`);
            }

            const data = await response.json();
            const content = data.response.trim();

            // Try to parse JSON
            try {
                const poseData = JSON.parse(content);
                conversationHistory.push({ input: text, output: JSON.stringify(poseData) });
                return poseData;
            } catch (parseError) {
                // Try to extract JSON from text
                const jsonMatch = content.match(/\{[\s\S]*\}/);
                if (jsonMatch) {
                    const poseData = JSON.parse(jsonMatch[0]);
                    conversationHistory.push({ input: text, output: JSON.stringify(poseData) });
                    return poseData;
                }
                throw new Error('Invalid JSON in Ollama response');
            }
        }

        async function generateWithLMStudio(text) {
            const baseUrl = document.getElementById('lmstudioUrl').value.trim() || 'http://localhost:1234';

            const messages = [
                {
                    role: 'user',
                    content: `Convert this pose description into specific IK target positions for a humanoid robot.
                    Description: "${text}"

                    Respond with JSON format like:
                    {
                        "leftHand": [x, y, z],
                        "rightHand": [x, y, z],
                        "description": "brief description"
                    }

                    Use coordinates relative to robot center, where:
                    - Forward is +Z, Back is -Z
                    - Right is +X, Left is -X
                    - Up is +Y, Down is -Y
                    - Normal reach distance is about 0.5-0.8 units

                    Examples:
                    "wave hello" -> {"leftHand": [0.6, 1.8, 0.4], "rightHand": [-0.6, 1.8, 0.4], "description": "waving both hands"}
                    "point forward" -> {"leftHand": [0.8, 1.2, 0.6], "rightHand": [-0.2, 0.8, 0.1], "description": "pointing with left hand"}`
                }
            ];

            const response = await fetch(`${baseUrl}/v1/chat/completions`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    messages: messages,
                    max_tokens: 300,
                    temperature: 0.3
                })
            });

            if (!response.ok) {
                throw new Error(`LM Studio API error: ${response.status}`);
            }

            const data = await response.json();
            const content = data.choices[0].message.content.trim();

            // Try to parse JSON
            try {
                const poseData = JSON.parse(content);
                conversationHistory.push({ input: text, output: JSON.stringify(poseData) });
                return poseData;
            } catch (parseError) {
                // Try to extract JSON from text
                const jsonMatch = content.match(/\{[\s\S]*\}/);
                if (jsonMatch) {
                    const poseData = JSON.parse(jsonMatch[0]);
                    conversationHistory.push({ input: text, output: JSON.stringify(poseData) });
                    return poseData;
                }
                throw new Error('Invalid JSON in LM Studio response');
            }
        }

        async function generateWithTogether(text) {
            const apiKey = document.getElementById('togetherKey').value.trim();
            if (!apiKey) {
                throw new Error('Together AI API key required');
            }

            const messages = [
                {
                    role: 'user',
                    content: `Convert this pose description into specific IK target positions for a humanoid robot.
                    Description: "${text}"

                    Respond with JSON format like:
                    {
                        "leftHand": [x, y, z],
                        "rightHand": [x, y, z],
                        "description": "brief description"
                    }

                    Use coordinates relative to robot center, where:
                    - Forward is +Z, Back is -Z
                    - Right is +X, Left is -X
                    - Up is +Y, Down is -Y
                    - Normal reach distance is about 0.5-0.8 units

                    Examples:
                    "wave hello" -> {"leftHand": [0.6, 1.8, 0.4], "rightHand": [-0.6, 1.8, 0.4], "description": "waving both hands"}
                    "point forward" -> {"leftHand": [0.8, 1.2, 0.6], "rightHand": [-0.2, 0.8, 0.1], "description": "pointing with left hand"}`
                }
            ];

            const response = await fetch('https://api.together.xyz/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${apiKey}`
                },
                body: JSON.stringify({
                    model: 'meta-llama/Llama-2-70b-chat-hf',
                    messages: messages,
                    max_tokens: 300,
                    temperature: 0.3
                })
            });

            if (!response.ok) {
                throw new Error(`Together AI API error: ${response.status}`);
            }

            const data = await response.json();
            const content = data.choices[0].message.content.trim();

            // Try to parse JSON
            try {
                const poseData = JSON.parse(content);
                conversationHistory.push({ input: text, output: JSON.stringify(poseData) });
                return poseData;
            } catch (parseError) {
                // Try to extract JSON from text
                const jsonMatch = content.match(/\{[\s\S]*\}/);
                if (jsonMatch) {
                    const poseData = JSON.parse(jsonMatch[0]);
                    conversationHistory.push({ input: text, output: JSON.stringify(poseData) });
                    return poseData;
                }
                throw new Error('Invalid JSON in Together AI response');
            }
        }

        function createPlaceholderYBot() {
            console.log('Creating rigged placeholder YBot with IK-ready skeleton...');

            // Create a simple humanoid with bones for IK
            ybot = new THREE.Group();
            ybot.name = 'YBot';

            // Create materials
            const bodyMaterial = new THREE.MeshLambertMaterial({ color: 0x4a90e2 });
            const limbMaterial = new THREE.MeshLambertMaterial({ color: 0x7ed321 });

            // Create body parts using available geometries
            const torsoGeometry = new THREE.CylinderGeometry(0.3, 0.25, 0.8, 8);
            const torso = new THREE.Mesh(torsoGeometry, bodyMaterial);
            torso.position.set(0, 0.4, 0);
            torso.castShadow = true;
            ybot.add(torso);

            // Create head
            const headGeometry = new THREE.SphereGeometry(0.15, 8, 6);
            const head = new THREE.Mesh(headGeometry, bodyMaterial);
            head.position.set(0, 0.9, 0);
            head.castShadow = true;
            ybot.add(head);

            // Create arms using cylinder geometry
            const armGeometry = new THREE.CylinderGeometry(0.08, 0.08, 0.4, 6);
            const leftArm = new THREE.Mesh(armGeometry, limbMaterial);
            leftArm.position.set(-0.4, 0.3, 0);
            leftArm.castShadow = true;
            ybot.add(leftArm);

            const rightArm = new THREE.Mesh(armGeometry, limbMaterial);
            rightArm.position.set(0.4, 0.3, 0);
            rightArm.castShadow = true;
            ybot.add(rightArm);

            // Create forearms
            const forearmGeometry = new THREE.CylinderGeometry(0.06, 0.06, 0.3, 6);
            const leftForearm = new THREE.Mesh(forearmGeometry, limbMaterial);
            leftForearm.position.set(-0.6, 0.1, 0);
            leftForearm.castShadow = true;
            ybot.add(leftForearm);

            const rightForearm = new THREE.Mesh(forearmGeometry, limbMaterial);
            rightForearm.position.set(0.6, 0.1, 0);
            rightForearm.castShadow = true;
            ybot.add(rightForearm);

            // Create hands (IK targets)
            const handGeometry = new THREE.SphereGeometry(0.05, 6, 4);
            const leftHandMesh = new THREE.Mesh(handGeometry, limbMaterial);
            leftHandMesh.position.set(-0.8, -0.1, 0);
            leftHandMesh.castShadow = true;
            ybot.add(leftHandMesh);

            const rightHandMesh = new THREE.Mesh(handGeometry, limbMaterial);
            rightHandMesh.position.set(0.8, -0.1, 0);
            rightHandMesh.castShadow = true;
            ybot.add(rightHandMesh);

            // Create legs
            const legGeometry = new THREE.CylinderGeometry(0.1, 0.1, 0.6, 8);
            const leftLeg = new THREE.Mesh(legGeometry, limbMaterial);
            leftLeg.position.set(-0.15, -0.6, 0);
            leftLeg.castShadow = true;
            ybot.add(leftLeg);

            const rightLeg = new THREE.Mesh(legGeometry, limbMaterial);
            rightLeg.position.set(0.15, -0.6, 0);
            rightLeg.castShadow = true;
            ybot.add(rightLeg);

            // Create feet
            const footGeometry = new THREE.BoxGeometry(0.12, 0.08, 0.25);
            const leftFoot = new THREE.Mesh(footGeometry, limbMaterial);
            leftFoot.position.set(-0.15, -1.0, 0.05);
            leftFoot.castShadow = true;
            ybot.add(leftFoot);

            const rightFoot = new THREE.Mesh(footGeometry, limbMaterial);
            rightFoot.position.set(0.15, -1.0, 0.05);
            rightFoot.castShadow = true;
            ybot.add(rightFoot);

            // Create a simple skeleton for IK
            ybot.skeleton = {
                bones: [
                    { name: 'Hips', position: new THREE.Vector3(0, 0, 0) },
                    { name: 'Spine', position: new THREE.Vector3(0, 0.2, 0) },
                    { name: 'Chest', position: new THREE.Vector3(0, 0.5, 0) },
                    { name: 'Neck', position: new THREE.Vector3(0, 0.7, 0) },
                    { name: 'Head', position: new THREE.Vector3(0, 0.9, 0) },
                    { name: 'LeftShoulder', position: new THREE.Vector3(-0.2, 0.6, 0) },
                    { name: 'LeftArm', position: new THREE.Vector3(-0.4, 0.4, 0) },
                    { name: 'LeftForeArm', position: new THREE.Vector3(-0.6, 0.2, 0) },
                    { name: 'LeftHand', position: new THREE.Vector3(-0.8, 0, 0) },
                    { name: 'RightShoulder', position: new THREE.Vector3(0.2, 0.6, 0) },
                    { name: 'RightArm', position: new THREE.Vector3(0.4, 0.4, 0) },
                    { name: 'RightForeArm', position: new THREE.Vector3(0.6, 0.2, 0) },
                    { name: 'RightHand', position: new THREE.Vector3(0.8, 0, 0) },
                    { name: 'LeftUpLeg', position: new THREE.Vector3(-0.15, -0.1, 0) },
                    { name: 'LeftLeg', position: new THREE.Vector3(-0.15, -0.5, 0) },
                    { name: 'LeftFoot', position: new THREE.Vector3(-0.15, -0.9, 0) },
                    { name: 'RightUpLeg', position: new THREE.Vector3(0.15, -0.1, 0) },
                    { name: 'RightLeg', position: new THREE.Vector3(0.15, -0.5, 0) },
                    { name: 'RightFoot', position: new THREE.Vector3(0.15, -0.9, 0) }
                ]
            };

            ybot.position.set(0, 1, 0);
            scene.add(ybot);
            console.log('Rigged placeholder YBot created with skeleton for IK');
        }
    </script>
</body>
</html>